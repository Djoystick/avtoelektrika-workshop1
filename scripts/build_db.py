#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üîß DB Builder v2.0 - –û–±—ä–µ–¥–∏–Ω—è–µ—Ç YouTube + Habr + –§–æ—Ä—É–º—ã + Community
"""

import json
import os
import glob
from datetime import datetime

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

def load_json_file(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return None

def load_community_solutions():
    solutions = []
    solutions_dir = os.path.join(PROJECT_ROOT, "db", "solutions")
    
    if not os.path.exists(solutions_dir):
        return solutions
    
    md_files = glob.glob(os.path.join(solutions_dir, "**", "*.md"), recursive=True)
    
    for md_file in md_files:
        if "README" in md_file:
            continue
        
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
                lines = content.split('\n')
                title = lines[0].replace('# ', '').strip() if lines else "Unknown"
                
                author = "Unknown"
                date_added = datetime.fromtimestamp(os.path.getmtime(md_file)).isoformat()
                marques = []
                
                for line in lines[1:10]:
                    if "–ê–≤—Ç–æ—Ä:" in line:
                        parts = line.split("**")
                        author = parts[1] if len(parts) > 1 else "Unknown"
                    if "–î–∞—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è:" in line:
                        parts = line.split("**")
                        date_added = parts[1] if len(parts) > 1 else date_added
                    if "–ú–∞—Ä–∫–∏ –∞–≤—Ç–æ:" in line:
                        parts = line.split("**")
                        if len(parts) > 1:
                            marques = [m.strip() for m in parts[1].split(",")]
                
                summary = '\n'.join([l for l in lines[10:20] if l.strip()])[:400]
                
                rel_path = os.path.relpath(md_file, solutions_dir)
                category = rel_path.split('/')[0].replace('_', ' ').title()
                
                solution = {
                    "id": f"community_{os.path.splitext(os.path.basename(md_file))[0]}",
                    "title": title,
                    "summary": summary,
                    "link": f"#{os.path.splitext(os.path.basename(md_file))[0]}",
                    "source": f"{author} (Community)",
                    "sourceType": "article",
                    "contentType": "üìñ –°—Ç–∞—Ç—å—è",
                    "category": f"ü§ù {category}",
                    "published": date_added,
                    "image": None,
                    "type": "community",
                    "brands": marques
                }
                solutions.append(solution)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {md_file}: {e}")
            continue
    
    return solutions

def build_db():
    print("üîß DB Builder v2.0\n")
    
    all_items = []
    
    # YouTube
    print("üì• –ó–∞–≥—Ä—É–∂–∞—é YouTube –≤–∏–¥–µ–æ...")
    yt_data = load_json_file(os.path.join(PROJECT_ROOT, "api-cache", "youtube-videos.json"))
    if yt_data and yt_data.get("videos"):
        all_items.extend(yt_data.get("videos", []))
        print(f"   ‚úÖ {len(yt_data.get('videos', []))} –≤–∏–¥–µ–æ")
    else:
        print(f"   ‚ö†Ô∏è  0 –≤–∏–¥–µ–æ")
    
    # Habr
    print("üì• –ó–∞–≥—Ä—É–∂–∞—é Habr —Å—Ç–∞—Ç—å–∏...")
    habr_data = load_json_file(os.path.join(PROJECT_ROOT, "api-cache", "habr-articles.json"))
    if habr_data and habr_data.get("articles"):
        all_items.extend(habr_data.get("articles", []))
        print(f"   ‚úÖ {len(habr_data.get('articles', []))} —Å—Ç–∞—Ç–µ–π")
    else:
        print(f"   ‚ö†Ô∏è  0 —Å—Ç–∞—Ç–µ–π")
    
    # –§–æ—Ä—É–º—ã RSS
    print("üì• –ó–∞–≥—Ä—É–∂–∞—é –ø–æ—Å—Ç—ã –∏–∑ —Ñ–æ—Ä—É–º–æ–≤ (RSS)...")
    forums_rss_data = load_json_file(os.path.join(PROJECT_ROOT, "api-cache", "forums-rss.json"))
    if forums_rss_data and forums_rss_data.get("posts"):
        all_items.extend(forums_rss_data.get("posts", []))
        print(f"   ‚úÖ {len(forums_rss_data.get('posts', []))} –ø–æ—Å—Ç–æ–≤")
    else:
        print(f"   ‚ö†Ô∏è  0 –ø–æ—Å—Ç–æ–≤ RSS")
    
    # –§–æ—Ä—É–º—ã HTML
    print("üì• –ó–∞–≥—Ä—É–∂–∞—é –ø–æ—Å—Ç—ã –∏–∑ HTML —Ñ–æ—Ä—É–º–æ–≤...")
    forums_html_data = load_json_file(os.path.join(PROJECT_ROOT, "api-cache", "forums-html.json"))
    if forums_html_data and forums_html_data.get("posts"):
        all_items.extend(forums_html_data.get("posts", []))
        print(f"   ‚úÖ {len(forums_html_data.get('posts', []))} –≤–æ–ø—Ä–æ—Å–æ–≤")
    else:
        print(f"   ‚ö†Ô∏è  0 –≤–æ–ø—Ä–æ—Å–æ–≤ HTML")
    
    # Community Solutions
    print("üì• –ó–∞–≥—Ä—É–∂–∞—é —Ä–µ—à–µ–Ω–∏—è —Å–æ–æ–±—â–µ—Å—Ç–≤–∞...")
    community = load_community_solutions()
    all_items.extend(community)
    print(f"   ‚úÖ {len(community)} —Ä–µ—à–µ–Ω–∏–π")
    
    if not all_items:
        print("\n‚ö†Ô∏è  –ù–ï –ù–ê–ô–î–ï–ù–û –ù–ò–ö–ê–ö–ò–• –ú–ê–¢–ï–†–ò–ê–õ–û–í!")
        return False
    
    # –°—Ç—Ä–æ–∏–º –∏–Ω–¥–µ–∫—Å—ã
    print("\nüî® –°—Ç—Ä–æ—é –∏–Ω–¥–µ–∫—Å—ã...")
    
    category_index = {}
    source_index = {}
    type_index = {}
    brand_index = {}
    
    for item in all_items:
        cat = item.get("category", "–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
        src = item.get("source", "Unknown")
        typ = item.get("type", "unknown")
        
        if cat not in category_index:
            category_index[cat] = []
        category_index[cat].append(item["id"])
        
        if src not in source_index:
            source_index[src] = []
        source_index[src].append(item["id"])
        
        if typ not in type_index:
            type_index[typ] = []
        type_index[typ].append(item["id"])
        
        for brand in item.get("brands", []):
            if brand not in brand_index:
                brand_index[brand] = []
            brand_index[brand].append(item["id"])
    
    all_items.sort(key=lambda x: x.get("published", ""), reverse=True)
    
    db = {
        "articles": all_items,
        "indexes": {
            "categories": category_index,
            "sources": source_index,
            "types": type_index,
            "brands": brand_index,
        },
        "stats": {
            "totalArticles": len(all_items),
            "totalCategories": len(category_index),
            "totalSources": len(source_index),
            "youtube": len([a for a in all_items if a.get("type") in ["youtube_search", "youtube_channel"]]),
            "habr": len([a for a in all_items if a.get("type") == "habr"]),
            "forums": len([a for a in all_items if a.get("type") in ["forum_rss", "forum_html"]]),
            "community": len([a for a in all_items if a.get("type") == "community"]),
        },
        "lastUpdated": datetime.now().isoformat(),
        "version": "5.2-forums"
    }
    
    output_file = os.path.join(PROJECT_ROOT, "db.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(db, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –ì–û–¢–û–í–û!")
    print(f"   üìä –í—Å–µ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {db['stats']['totalArticles']}")
    print(f"   üé¨ YouTube –≤–∏–¥–µ–æ: {db['stats']['youtube']}")
    print(f"   üìö Habr —Å—Ç–∞—Ç—å–∏: {db['stats']['habr']}")
    print(f"   üí¨ –ü–æ—Å—Ç—ã –∏–∑ —Ñ–æ—Ä—É–º–æ–≤: {db['stats']['forums']}")
    print(f"   ü§ù Community —Ä–µ—à–µ–Ω–∏—è: {db['stats']['community']}")
    
    return True

if __name__ == "__main__":
    import sys
    sys.exit(0 if build_db() else 1)
