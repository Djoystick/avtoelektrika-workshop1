#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üîß –ú–∞—Å—Ç–µ—Ä—Å–∫–∞—è –ê–≤—Ç–æ—ç–ª–µ–∫—Ç—Ä–∏–∫–∞ - –ü–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π v2.0
–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ 100+ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Å–∏–º–ø—Ç–æ–º–æ–≤
"""

import feedparser
import json
import sys
import os
import re
from datetime import datetime
from urllib.parse import urlparse

# –ü–æ–¥–∫–ª—é—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from config import (
        NEWS_SOURCES,
        MAX_NEWS_PER_SOURCE,
        MAX_TOTAL_NEWS,
        EXCLUDE_KEYWORDS,
        TECH_KEYWORDS,
        SYMPTOMS_KEYWORDS,
        OUTPUT_FILE,
        PROJECT_ROOT
    )
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ config: {e}")
    sys.exit(1)

# ============================================
# –¶–í–ï–¢–ê –î–õ–Ø –ö–û–ù–°–û–õ–ò
# ============================================

class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    END = '\033[0m'
    BOLD = '\033[1m'

# ============================================
# –§–£–ù–ö–¶–ò–ò –§–ò–õ–¨–¢–†–ê–¶–ò–ò
# ============================================

def is_technical(title, summary):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–æ–≤–æ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ –∞–≤—Ç–æ—ç–ª–µ–∫—Ç—Ä–∏–∫–µ"""
    text = (title + " " + summary).lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (–∏—Å–∫–ª—é—á–∞–µ–º)
    for keyword in EXCLUDE_KEYWORDS:
        if keyword.lower() in text:
            return False
    
    # –°—á–∏—Ç–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞
    tech_count = 0
    for keyword in TECH_KEYWORDS:
        if keyword.lower() in text:
            tech_count += 1
    
    # –¢—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 1 —Ç–µ—Ö–Ω–æ-—Å–ª–æ–≤–æ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
    return tech_count >= 1

def extract_symptoms(title, summary):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–º–ø—Ç–æ–º—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏"""
    text = (title + " " + summary).lower()
    found_symptoms = []
    
    for symptom in SYMPTOMS_KEYWORDS:
        if symptom.lower() in text:
            found_symptoms.append(symptom)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    found_symptoms = list(set(found_symptoms))
    found_symptoms.sort(key=lambda x: len(x), reverse=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞–∫—Å–∏–º—É–º 10 —Å–∏–º–ø—Ç–æ–º–æ–≤
    return found_symptoms[:10]

def extract_image(entry):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ RSS entry"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º media:content
    if hasattr(entry, 'media_content') and entry.media_content:
        try:
            return entry.media_content[0].get('url', '')
        except:
            pass
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º media:thumbnail
    if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail:
        try:
            return entry.media_thumbnail[0].get('url', '')
        except:
            pass
    
    # –ò—â–µ–º img –≤ summary
    if 'summary' in entry:
        try:
            img_match = re.search(r'<img[^>]*src=["\'](.*?)["\']', entry.summary)
            if img_match:
                return img_match.group(1)
        except:
            pass
    
    return None

def clean_html(text):
    """–û—á–∏—â–∞–µ—Ç HTML —Ç–µ–≥–∏ –∏ —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return ''
    
    # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
    text = re.sub(r'<[^>]+>', '', text)
    
    # –ó–∞–º–µ–Ω—è–µ–º HTML entities
    entities = {
        '&nbsp;': ' ',
        '&quot;': '"',
        '&apos;': "'",
        '&amp;': '&',
        '&lt;': '<',
        '&gt;': '>',
        '&#39;': "'",
        '<br': ' ',
        '</br>': ' ',
        '</p>': ' ',
        '</div>': ' ',
    }
    
    for entity, char in entities.items():
        text = text.replace(entity, char)
    
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text).strip()
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    if len(text) > 500:
        text = text[:500]
    
    return text

def shorten_text(text, max_length=200):
    """–°–æ–∫—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π –¥–ª–∏–Ω—ã"""
    if len(text) > max_length:
        # –û–±—Ä–µ–∑–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º –ø–æ–ª–Ω–æ–º —Å–ª–æ–≤–µ
        shortened = text[:max_length].rsplit(' ', 1)[0]
        return shortened + '...'
    return text

# ============================================
# –ü–ê–†–°–ò–ù–ì RSS
# ============================================

def parse_rss_feed(source, source_number, total_sources):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω RSS –∏—Å—Ç–æ—á–Ω–∏–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    news_list = []
    
    try:
        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ—Ü–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞
        source_name = source['name'][:40]
        print(f"  [{source_number:3d}/{total_sources}] ", end='')
        print(f"{Colors.CYAN}üì•{Colors.END} {source_name:<40} ", end='', flush=True)
        
        # –ü–∞—Ä—Å–∏–º RSS
        feed = feedparser.parse(source['url'])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏
        if feed.bozo:
            print(f"{Colors.YELLOW}‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞{Colors.END}")
            return news_list
        
        if not feed.entries:
            print(f"{Colors.YELLOW}‚ö†Ô∏è  –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π{Colors.END}")
            return news_list
        
        valid_count = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç–∞—Ç—å—é
        for entry in feed.entries[:MAX_NEWS_PER_SOURCE]:
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ entry
                title = entry.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')
                summary = entry.get('summary', '')
                link = entry.get('link', '')
                published = entry.get('published', '')
                
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
                title = clean_html(title)
                summary = clean_html(summary)
                summary = shorten_text(summary, 200)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                if not title:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ª–∏ –Ω–æ–≤–æ—Å—Ç—å
                if not is_technical(title, summary):
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–ø—Ç–æ–º—ã
                symptoms = extract_symptoms(title, summary)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                image = extract_image(entry)
                
                # –°–æ–∑–¥–∞—ë–º —ç–ª–µ–º–µ–Ω—Ç –Ω–æ–≤–æ—Å—Ç–∏
                news_item = {
                    'title': title,
                    'summary': summary,
                    'link': link,
                    'source': source['name'],
                    'category': source['category'],
                    'symptoms': symptoms,
                    'image': image,
                    'published': published,
                }
                
                news_list.append(news_item)
                valid_count += 1
                
            except Exception as e:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—à–∏–±–æ—á–Ω—ã–µ entries
                continue
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if valid_count > 0:
            print(f"{Colors.GREEN}‚úÖ{Colors.END} {valid_count} —Å—Ç–∞—Ç–µ–π")
        else:
            print(f"{Colors.YELLOW}‚ö†Ô∏è  0 —Å—Ç–∞—Ç–µ–π{Colors.END}")
        
    except Exception as e:
        print(f"{Colors.RED}‚ùå –û—à–∏–±–∫–∞: {str(e)[:30]}{Colors.END}")
    
    return news_list

def fetch_all_news():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    all_news = []
    
    # –í—ã–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    print(f"\n{Colors.BOLD}{Colors.BLUE}{'='*70}{Colors.END}")
    print(f"{Colors.BOLD}üîß –ú–∞—Å—Ç–µ—Ä—Å–∫–∞—è –ê–≤—Ç–æ—ç–ª–µ–∫—Ç—Ä–∏–∫–∞ v2.0 - –ü–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π{Colors.END}")
    print(f"{Colors.BLUE}{'='*70}{Colors.END}")
    print(f"‚è±Ô∏è  –ù–∞—á–∞–ª–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üì° –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(NEWS_SOURCES)}")
    print(f"üìä –ú–∞–∫—Å–∏–º—É–º —Å—Ç–∞—Ç–µ–π: {MAX_TOTAL_NEWS}")
    print(f"{Colors.BLUE}{'='*70}{Colors.END}\n")
    
    # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
    for idx, source in enumerate(NEWS_SOURCES, 1):
        news = parse_rss_feed(source, idx, len(NEWS_SOURCES))
        all_news.extend(news)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    all_news.sort(
        key=lambda x: x.get('published', ''),
        reverse=True
    )
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    all_news = all_news[:MAX_TOTAL_NEWS]
    
    print(f"\n{Colors.BLUE}{'='*70}{Colors.END}")
    print(f"{Colors.GREEN}‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(all_news)}{Colors.END}")
    
    return all_news

# ============================================
# –°–û–•–†–ê–ù–ï–ù–ò–ï –í JSON
# ============================================

def save_news_to_json(news_list):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ JSON —Ñ–∞–π–ª"""
    try:
        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        categories = set(n['category'] for n in news_list)
        sources = set(n['source'] for n in news_list)
        all_symptoms = []
        for n in news_list:
            all_symptoms.extend(n.get('symptoms', []))
        symptoms = set(all_symptoms)
        
        output_data = {
            'news': news_list,
            'lastUpdated': datetime.now().isoformat(),
            'totalItems': len(news_list),
            'totalSources': len(sources),
            'totalCategories': len(categories),
            'totalSymptoms': len(symptoms),
        }
        
        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        file_size = os.path.getsize(OUTPUT_FILE) / 1024
        print(f"{Colors.GREEN}üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {OUTPUT_FILE}{Colors.END}")
        print(f"   –†–∞–∑–º–µ—Ä: {file_size:.1f} KB")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(categories)}")
        print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(sources)}")
        print(f"   –°–∏–º–ø—Ç–æ–º–æ–≤: {len(symptoms)}\n")
        
        return True
        
    except Exception as e:
        print(f"{Colors.RED}‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}{Colors.END}\n")
        return False

# ============================================
# –°–¢–ê–¢–ò–°–¢–ò–ö–ê
# ============================================

def print_statistics(news_list):
    """–í—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–æ–±—Ä–∞–Ω–Ω—ã–º –Ω–æ–≤–æ—Å—Ç—è–º"""
    print(f"\n{Colors.BOLD}üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê{Colors.END}")
    print(f"{Colors.BLUE}{'='*70}{Colors.END}")
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"üìù –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {len(news_list)}")
    
    # –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    categories = {}
    for item in news_list:
        cat = item.get('category', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        categories[cat] = categories.get(cat, 0) + 1
    
    print(f"\nüìÇ –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ({len(categories)}):")
    for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:15]:
        print(f"   {cat:40} {count:3d} —Å—Ç–∞—Ç–µ–π")
    
    # –ü–æ —Å–∏–º–ø—Ç–æ–º–∞–º
    symptoms_count = {}
    for item in news_list:
        for symptom in item.get('symptoms', []):
            symptoms_count[symptom] = symptoms_count.get(symptom, 0) + 1
    
    print(f"\nüè∑Ô∏è  –¢–æ–ø —Å–∏–º–ø—Ç–æ–º–æ–≤ ({len(symptoms_count)}):")
    for symptom, count in sorted(symptoms_count.items(), key=lambda x: x[1], reverse=True)[:12]:
        print(f"   {symptom:45} {count:3d} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
    
    # –ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
    sources = {}
    for item in news_list:
        src = item.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        sources[src] = sources.get(src, 0) + 1
    
    print(f"\nüìå –ê–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(sources)}")
    
    print(f"\n{Colors.BLUE}{'='*70}{Colors.END}\n")

# ============================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
    try:
        # –ü–∞—Ä—Å–∏–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        news = fetch_all_news()
        
        if not news:
            print(f"{Colors.RED}‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏{Colors.END}\n")
            sys.exit(1)
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print_statistics(news)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        if not save_news_to_json(news):
            sys.exit(1)
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        print(f"{Colors.GREEN}{Colors.BOLD}‚úÖ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û{Colors.END}")
        print(f"‚è±Ô∏è  –ö–æ–Ω–µ—Ü: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        return 0
        
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}‚èπÔ∏è  –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º{Colors.END}\n")
        return 1
    except Exception as e:
        print(f"\n{Colors.RED}{Colors.BOLD}‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}{Colors.END}\n")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    sys.exit(main())
