#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üé¨ YouTube Parser v1.0 - –í—ã—Ç—è–≥–∏–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –≤–∏–¥–µ–æ –ø–æ —Ä–µ–º–æ–Ω—Ç—É
"""

import feedparser
import json
import os
from datetime import datetime
from urllib.parse import urlparse, parse_qs

YOUTUBE_SEARCHES = [
    "—Ä–µ–º–æ–Ω—Ç —Å—Ç–∞—Ä—Ç–µ—Ä–∞",
    "–∑–∞–º–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞",
    "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫ obd2",
    "–∫–∞–∫ –Ω–∞–π—Ç–∏ —É—Ç–µ—á–∫—É —Ç–æ–∫–∞",
    "–∑–∞–º–µ–Ω–∞ —Å–≤–µ—á–µ–π –∑–∞–∂–∏–≥–∞–Ω–∏—è",
    "—Ä–µ–º–æ–Ω—Ç –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä–∞",
    "–ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞",
    "–∑–∞–º–µ–Ω–∞ –ø—Ä–æ–≤–æ–¥–æ–≤ –∑–∞–∂–∏–≥–∞–Ω–∏—è",
    "—Ä–µ–º–æ–Ω—Ç –∫–∞—Ç—É—à–∫–∏ –∑–∞–∂–∏–≥–∞–Ω–∏—è",
    "–∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è elm327",
]

YOUTUBE_CHANNELS = [
    ("–ò–ª—å–¥–∞—Ä –ê–≤—Ç–æ", "UCwP0lGe7yC-v3V_q-Oq-jHw"),
    ("–ì–∞—Ä–∞–∂ 54", "UCb0P2k5f77n6yGzJ6r6R78A"),
    ("–í –≥–∞—Ä–∞–∂–µ —É –°–∞–Ω–¥—Ä–æ", "UCqJqV8e8t7wz_xK9y6Vq_5g"),
]

def get_video_id(link):
    try:
        if "youtube.com" in link:
            parsed = urlparse(link)
            params = parse_qs(parsed.query)
            return params.get('v', [None])[0]
    except:
        pass
    return None

def parse_youtube_search(query):
    try:
        rss_url = f"https://www.youtube.com/feeds/videos.xml?search_query={query.replace(' ', '+')}"
        feed = feedparser.parse(rss_url)
        
        videos = []
        for entry in feed.entries[:10]:
            try:
                video_id = get_video_id(entry.link)
                thumbnail = f"https://img.youtube.com/vi/{video_id}/hqdefault.jpg" if video_id else None
                
                video = {
                    "id": f"yt_{video_id}",
                    "title": entry.title,
                    "summary": entry.summary[:300] if hasattr(entry, 'summary') else "",
                    "link": entry.link,
                    "source": "YouTube",
                    "sourceType": "video",
                    "contentType": "üé¨ –í–∏–¥–µ–æ",
                    "category": "üé¨ YouTube",
                    "published": entry.published if hasattr(entry, 'published') else datetime.now().isoformat(),
                    "image": thumbnail,
                    "type": "youtube_search"
                }
                videos.append(video)
            except:
                continue
        
        return videos
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –ø–æ–∏—Å–∫–∞ '{query}': {e}")
        return []

def parse_youtube_channel(channel_name, channel_id):
    try:
        rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
        feed = feedparser.parse(rss_url)
        
        videos = []
        for entry in feed.entries[:5]:
            try:
                video_id = get_video_id(entry.link)
                thumbnail = f"https://img.youtube.com/vi/{video_id}/hqdefault.jpg" if video_id else None
                
                video = {
                    "id": f"yt_{video_id}",
                    "title": entry.title,
                    "summary": entry.summary[:300] if hasattr(entry, 'summary') else "",
                    "link": entry.link,
                    "source": channel_name,
                    "sourceType": "video",
                    "contentType": "üé¨ –í–∏–¥–µ–æ",
                    "category": "üé¨ YouTube –ö–∞–Ω–∞–ª—ã",
                    "published": entry.published if hasattr(entry, 'published') else datetime.now().isoformat(),
                    "image": thumbnail,
                    "type": "youtube_channel"
                }
                videos.append(video)
            except:
                continue
        
        return videos
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞–Ω–∞–ª–∞ '{channel_name}': {e}")
        return []

def main():
    all_videos = []
    
    print("üé¨ YouTube Parser v1.0\n")
    
    print("üì• –ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–∏—Å–∫–æ–≤ YouTube...")
    for search in YOUTUBE_SEARCHES:
        videos = parse_youtube_search(search)
        all_videos.extend(videos)
        if videos:
            print(f"   ‚úÖ '{search}': {len(videos)} –≤–∏–¥–µ–æ")
    
    print("\nüì∫ –ü–∞—Ä—Å–∏–Ω–≥ YouTube –∫–∞–Ω–∞–ª–æ–≤...")
    for channel_name, channel_id in YOUTUBE_CHANNELS:
        videos = parse_youtube_channel(channel_name, channel_id)
        all_videos.extend(videos)
        if videos:
            print(f"   ‚úÖ {channel_name}: {len(videos)} –≤–∏–¥–µ–æ")
    
    seen_ids = set()
    unique_videos = []
    for video in all_videos:
        if video['id'] not in seen_ids:
            seen_ids.add(video['id'])
            unique_videos.append(video)
    
    all_videos = unique_videos
    
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    output_dir = os.path.join(project_root, "api-cache")
    output_file = os.path.join(output_dir, "youtube-videos.json")
    
    os.makedirs(output_dir, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "videos": all_videos,
            "count": len(all_videos),
            "lastUpdated": datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(all_videos)} –≤–∏–¥–µ–æ")
    return True

if __name__ == "__main__":
    import sys
    sys.exit(0 if main() else 1)
